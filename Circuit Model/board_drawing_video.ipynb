{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatAngle(boardBW):\n",
    "    \n",
    "\tcoords = np.column_stack(np.where(boardBW > 0))\n",
    "\tangle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "\tif angle < -45:\n",
    "\t\tangle = -(90 + angle)\n",
    "\t \n",
    "\telse:\n",
    "\t\tangle = -angle\n",
    "\t\t\n",
    "\treturn angle\n",
    "\n",
    "\n",
    "def tilt(image, angle):\n",
    "\t# rotate the image to deskew it\n",
    "\t(h, w) = image.shape[:2]\n",
    "\tcenter = (w // 2, h // 2)\n",
    "\tM = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\trotated = cv2.warpAffine(image, M, (w, h),\n",
    "\tflags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\treturn rotated\n",
    "\n",
    "\n",
    "def get_edges(image):\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Get the indices of non-zero elements (edge points)\n",
    "    non_zero_indices = np.nonzero(image_array)\n",
    "\n",
    "    # Get the minimum and maximum row and column indices of non-zero elements\n",
    "    minRow, minColumn = np.min(non_zero_indices, axis=1)\n",
    "    maxRow, maxColumn = np.max(non_zero_indices, axis=1)\n",
    "\n",
    "    extLeft = minColumn\n",
    "    extRight = maxColumn\n",
    "    extTop = minRow\n",
    "    extBot = maxRow\n",
    "    return (extLeft, extRight, extBot, extTop)\n",
    "\n",
    "def get_board_mask(img):\n",
    "    color = [0, 0, 0, 255, 255, 50]\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array(color[:3])  \n",
    "    upper = np.array(color[3:]) \n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def get_pegs(img,x1,x2,y1,y2):\n",
    "    matrixcoor_to_realcoor = {}\n",
    "    dist_from_edge = [(x2-x1)/13,(y2-y1)/15]\n",
    "    board_width = x2-x1-2*dist_from_edge[0]\n",
    "    board_height = y2-y1-2*dist_from_edge[1]\n",
    "    horizontal_interval = board_width / 12\n",
    "    vertical_interval = board_height / 14\n",
    "    img_circle = img.copy()\n",
    "    \n",
    "    # relate matrix coordinate to real peg coordinate\n",
    "    for i in range(0,13):\n",
    "        for j in range(0,15):\n",
    "            matrixcoor_to_realcoor[i,j] = np.array([x1 + int(horizontal_interval * i + dist_from_edge[0]), y1 + int(vertical_interval * j + dist_from_edge[1])])\n",
    "    \n",
    "    for key in matrixcoor_to_realcoor:\n",
    "        cv2.circle(img_circle, matrixcoor_to_realcoor[key], 2, (200, 200, 200), -1)\n",
    "    \n",
    "    return img_circle,matrixcoor_to_realcoor\n",
    "\n",
    "def draws_pegs_on_rotated_board(image,draw_edge=False):\n",
    "    #time1=time.time()\n",
    "    boardBW = get_board_mask(image)\n",
    "    angle = whatAngle(boardBW)\n",
    "    #time2=time.time()\n",
    "    #print(\"masking and calculate angle time:\", time2-time1)\n",
    "    boardBW_tilt = tilt(boardBW, angle) \n",
    "    image_tilt = tilt(image, angle) \n",
    "    #time3=time.time()\n",
    "    #print(\"deskew time:\", time3-time2)\n",
    "    # cv2.imwrite('board_deskew.png',image_tilt)  \n",
    "            \n",
    "    #get the max edges of the board then draw edges and pegs on it\n",
    "    x1,x2,y1,y2 = get_edges(boardBW_tilt)\n",
    "    #time4=time.time()\n",
    "    #print(\"get_edges:\", time4-time3)\n",
    "    img_circle, matrixcoor_to_realcoor = get_pegs(image_tilt,x1,x2,y1,y2)\n",
    "    #time5=time.time()\n",
    "    #print(\"get_pegs:\", time5-time4)\n",
    "    \n",
    "    if draw_edge:\n",
    "        cv2.rectangle(img_circle, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "    # cv2.imwrite('board_with_pegs.png',img_circle)    \n",
    "    return matrixcoor_to_realcoor, image_tilt, img_circle\n",
    "\n",
    "def round_to_integer_with_error(float_number, error_rate = 0.1, down = True):\n",
    "    if down:\n",
    "        lower_integer = int(float_number)\n",
    "\n",
    "        # Calculate the error between the float number and the lower integer\n",
    "        error = float_number - lower_integer\n",
    "\n",
    "        # Check if the error is within the custom error rate\n",
    "        if error <= error_rate:\n",
    "            return lower_integer - 1\n",
    "        else:\n",
    "            return lower_integer \n",
    "    else:\n",
    "        upper_integer = np.ceil(float_number).astype(int)\n",
    "\n",
    "        # Calculate the error between the float number and the upper integer\n",
    "        error = upper_integer - float_number\n",
    "\n",
    "        # Check if the error is within the custom error rate\n",
    "        if error <= error_rate:\n",
    "            return upper_integer + 1\n",
    "        else:\n",
    "            return upper_integer\n",
    "        \n",
    "def matrix_class_mapping(results,matrixcoor_to_realcoor):\n",
    "    x0,y0 = matrixcoor_to_realcoor[(0,14)]\n",
    "    matrix = np.zeros((13, 15))-1\n",
    "    x_len, y_len = np.abs(matrixcoor_to_realcoor[(0,0)]-matrixcoor_to_realcoor[(12,14)])\n",
    "\n",
    "    for r in results:\n",
    "        x1,y1,x2,y2,class_id = r\n",
    "        grid_x1 = round_to_integer_with_error(((x1-x0) / x_len) * 12,down=False)\n",
    "        grid_y1 = round_to_integer_with_error(((y1-y0) / y_len) * 14,down=False)\n",
    "        grid_x2 = round_to_integer_with_error(((x2-x0) / x_len) * 12)\n",
    "        grid_y2 = round_to_integer_with_error(((y2-y0) / y_len) * 14)\n",
    "\n",
    "        grid_x1 = max(0, min(grid_x1, 12 - 1))\n",
    "        grid_y1 = max(0, min(grid_y1, 14 - 1))\n",
    "        grid_x2 = max(0, min(grid_x2, 12 - 1))\n",
    "        grid_y2 = max(0, min(grid_y2, 14 - 1))\n",
    "\n",
    "        matrix[grid_x1:grid_x2+1,grid_y1:grid_y2+1]=class_id\n",
    "    return matrix\n",
    "\n",
    "color_mapping = {\n",
    "    0: 'red', # done, battery\n",
    "    1: 'black', # board\n",
    "    2: 'green', # done, buzzer\n",
    "    3: 'orange',\n",
    "    4: 'limegreen', #done, fm\n",
    "    5: 'white', # done (lamp; check accuracy)\n",
    "    6: 'darkred', # done, led\n",
    "    7: 'blue', # mc\n",
    "    8: 'yellow', # done, motor\n",
    "    9: 'royalblue', # done, push button\n",
    "    10: 'seagreen', # done, reed\n",
    "    11: 'firebrick', # done, speaker\n",
    "    12: 'darkgreen', # done, switch\n",
    "    13: 'purple' # done, wire\n",
    "}\n",
    "\n",
    "def show_estimated_board(results_transferred,color_mapping=color_mapping,rows = 13,cols = 15,cell_size = 50):\n",
    "    \"\"\"Draw the virtual image of the board\n",
    "\n",
    "    Args:\n",
    "        results_transferred (matrix): a matrix to store class of each block of the board\n",
    "        rows (int, optional): number of rows of the grid. Defaults to 8.\n",
    "        cols (int, optional): number of columns of the grid. Defaults to 7.\n",
    "        cell_size (int, optional): size of cell. Defaults to 50.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total size of the image\n",
    "    image_width = cols * cell_size\n",
    "    image_height = rows * cell_size\n",
    "\n",
    "    # Create a new image with a black background\n",
    "    image = Image.new(\"RGB\", (image_width, image_height), color=\"black\")\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Draw the grid with numbers\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate the position of the top-left corner of the cell\n",
    "            x1 = col * cell_size\n",
    "            y1 = row * cell_size\n",
    "\n",
    "            # Calculate the position of the bottom-right corner of the cell\n",
    "            x2 = x1 + cell_size\n",
    "            y2 = y1 + cell_size\n",
    "\n",
    "            # Calculate the number for each cell (you can use any logic here)\n",
    "            cell_number = results_transferred[row][col]\n",
    "\n",
    "            # Draw the cell with the corresponding number\n",
    "            if cell_number >= 0:\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=color_mapping[cell_number],outline='white')\n",
    "            else:\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=\"black\",outline='white')\n",
    "            draw.text((x1 + 20, y1 + 20), str(cell_number),  fill=\"white\")\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the image using cv2.imread()\n",
    "# image_path = 'raw11.png'\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # Get the necessary images and mapping using draws_pegs_on_rotated_board\n",
    "# matrixcoor_to_realcoor, image_tilt, img_circle = draws_pegs_on_rotated_board(image)\n",
    "\n",
    "# # Convert the image_tilt and img_circle (NumPy arrays) to PIL Image objects for display\n",
    "# image_tilt_pil = Image.fromarray(cv2.cvtColor(image_tilt, cv2.COLOR_BGR2RGB))\n",
    "# img_circle_pil = Image.fromarray(cv2.cvtColor(img_circle, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# # Display the images\n",
    "# image_tilt_pil.show()\n",
    "# img_circle_pil.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "1. Wires not very accurate (more training or use masking)\n",
    "2. Too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0 starts\n",
      "Draw pegs uses: 0.09071993827819824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.2793159484863281\n",
      "Frame {i} ends, using: 0.3816671371459961\n",
      "Frame 1 starts\n",
      "Draw pegs uses: 0.08118009567260742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 135.8ms\n",
      "Speed: 1.9ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.16880297660827637\n",
      "Frame {i} ends, using: 0.25316286087036133\n",
      "Frame 2 starts\n",
      "Draw pegs uses: 0.07907295227050781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 130.5ms\n",
      "Speed: 1.8ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15828299522399902\n",
      "Frame {i} ends, using: 0.23987770080566406\n",
      "Frame 3 starts\n",
      "Draw pegs uses: 0.07722687721252441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 126.3ms\n",
      "Speed: 2.1ms preprocess, 126.3ms inference, 0.6ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1526200771331787\n",
      "Frame {i} ends, using: 0.2321009635925293\n",
      "Frame 4 starts\n",
      "Draw pegs uses: 0.07754278182983398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 126.2ms\n",
      "Speed: 1.7ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15159320831298828\n",
      "Frame {i} ends, using: 0.23160481452941895\n",
      "Frame 5 starts\n",
      "Draw pegs uses: 0.07850193977355957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 led, 1 reed, 1 wire, 125.6ms\n",
      "Speed: 1.9ms preprocess, 125.6ms inference, 0.6ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1529068946838379\n",
      "Frame {i} ends, using: 0.23399615287780762\n",
      "Frame 6 starts\n",
      "Draw pegs uses: 0.08020877838134766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 125.1ms\n",
      "Speed: 2.8ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15116500854492188\n",
      "Frame {i} ends, using: 0.23361587524414062\n",
      "Frame 7 starts\n",
      "Draw pegs uses: 0.07731890678405762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 124.5ms\n",
      "Speed: 2.1ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1502699851989746\n",
      "Frame {i} ends, using: 0.23021578788757324\n",
      "Frame 8 starts\n",
      "Draw pegs uses: 0.07812714576721191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 led, 1 reed, 1 wire, 126.2ms\n",
      "Speed: 1.7ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15081095695495605\n",
      "Frame {i} ends, using: 0.2315351963043213\n",
      "Frame 9 starts\n",
      "Draw pegs uses: 0.07884693145751953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 reed, 1 wire, 123.9ms\n",
      "Speed: 1.8ms preprocess, 123.9ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15239977836608887\n",
      "Frame {i} ends, using: 0.23351192474365234\n",
      "Frame 10 starts\n",
      "Draw pegs uses: 0.0788569450378418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 reed, 1 wire, 123.4ms\n",
      "Speed: 1.7ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1470050811767578\n",
      "Frame {i} ends, using: 0.22844982147216797\n",
      "Frame 11 starts\n",
      "Draw pegs uses: 0.07875823974609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 127.1ms\n",
      "Speed: 2.0ms preprocess, 127.1ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15013384819030762\n",
      "Frame {i} ends, using: 0.23153996467590332\n",
      "Frame 12 starts\n",
      "Draw pegs uses: 0.08140683174133301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 led, 1 reed, 1 wire, 128.8ms\n",
      "Speed: 1.6ms preprocess, 128.8ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15283203125\n",
      "Frame {i} ends, using: 0.23675894737243652\n",
      "Frame 13 starts\n",
      "Draw pegs uses: 0.07952594757080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 led, 1 reed, 1 wire, 126.7ms\n",
      "Speed: 1.7ms preprocess, 126.7ms inference, 0.6ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15138721466064453\n",
      "Frame {i} ends, using: 0.23368215560913086\n",
      "Frame 14 starts\n",
      "Draw pegs uses: 0.07835912704467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 reed, 1 wire, 125.3ms\n",
      "Speed: 1.7ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1518540382385254\n",
      "Frame {i} ends, using: 0.2328510284423828\n",
      "Frame 15 starts\n",
      "Draw pegs uses: 0.07823801040649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 124.7ms\n",
      "Speed: 1.7ms preprocess, 124.7ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15005898475646973\n",
      "Frame {i} ends, using: 0.23065996170043945\n",
      "Frame 16 starts\n",
      "Draw pegs uses: 0.07875204086303711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 126.2ms\n",
      "Speed: 1.7ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1488208770751953\n",
      "Frame {i} ends, using: 0.2306361198425293\n",
      "Frame 17 starts\n",
      "Draw pegs uses: 0.0783231258392334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 126.8ms\n",
      "Speed: 1.7ms preprocess, 126.8ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15105986595153809\n",
      "Frame {i} ends, using: 0.23183512687683105\n",
      "Frame 18 starts\n",
      "Draw pegs uses: 0.0787210464477539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 128.6ms\n",
      "Speed: 1.8ms preprocess, 128.6ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15326285362243652\n",
      "Frame {i} ends, using: 0.2350940704345703\n",
      "Frame 19 starts\n",
      "Draw pegs uses: 0.07871890068054199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 reed, 1 wire, 131.6ms\n",
      "Speed: 1.7ms preprocess, 131.6ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1558060646057129\n",
      "Frame {i} ends, using: 0.2367689609527588\n",
      "Frame 20 starts\n",
      "Draw pegs uses: 0.07831597328186035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 reed, 1 wire, 128.8ms\n",
      "Speed: 1.9ms preprocess, 128.8ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1519320011138916\n",
      "Frame {i} ends, using: 0.23302602767944336\n",
      "Frame 21 starts\n",
      "Draw pegs uses: 0.07834410667419434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 125.7ms\n",
      "Speed: 1.7ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.14986395835876465\n",
      "Frame {i} ends, using: 0.2310481071472168\n",
      "Frame 22 starts\n",
      "Draw pegs uses: 0.08007001876831055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 124.6ms\n",
      "Speed: 1.7ms preprocess, 124.6ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.14833402633666992\n",
      "Frame {i} ends, using: 0.23105812072753906\n",
      "Frame 23 starts\n",
      "Draw pegs uses: 0.07896995544433594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 130.1ms\n",
      "Speed: 2.1ms preprocess, 130.1ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15424704551696777\n",
      "Frame {i} ends, using: 0.23553991317749023\n",
      "Frame 24 starts\n",
      "Draw pegs uses: 0.07866787910461426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 128.3ms\n",
      "Speed: 2.1ms preprocess, 128.3ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15234589576721191\n",
      "Frame {i} ends, using: 0.23353886604309082\n",
      "Frame 25 starts\n",
      "Draw pegs uses: 0.07931995391845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 127.4ms\n",
      "Speed: 1.7ms preprocess, 127.4ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15238618850708008\n",
      "Frame {i} ends, using: 0.23421788215637207\n",
      "Frame 26 starts\n",
      "Draw pegs uses: 0.07790684700012207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 130.2ms\n",
      "Speed: 1.7ms preprocess, 130.2ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1530170440673828\n",
      "Frame {i} ends, using: 0.23357105255126953\n",
      "Frame 27 starts\n",
      "Draw pegs uses: 0.07879281044006348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 127.8ms\n",
      "Speed: 1.7ms preprocess, 127.8ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15439605712890625\n",
      "Frame {i} ends, using: 0.2356276512145996\n",
      "Frame 28 starts\n",
      "Draw pegs uses: 0.07886791229248047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 129.3ms\n",
      "Speed: 1.7ms preprocess, 129.3ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15401697158813477\n",
      "Frame {i} ends, using: 0.2362501621246338\n",
      "Frame 29 starts\n",
      "Draw pegs uses: 0.07945513725280762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 127.1ms\n",
      "Speed: 1.9ms preprocess, 127.1ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15169787406921387\n",
      "Frame {i} ends, using: 0.2336268424987793\n",
      "Frame 30 starts\n",
      "Draw pegs uses: 0.08175897598266602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 135.5ms\n",
      "Speed: 2.1ms preprocess, 135.5ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15953493118286133\n",
      "Frame {i} ends, using: 0.2436380386352539\n",
      "Frame 31 starts\n",
      "Draw pegs uses: 0.08570694923400879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 led, 1 reed, 1 wire, 154.0ms\n",
      "Speed: 1.9ms preprocess, 154.0ms inference, 0.9ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.17880702018737793\n",
      "Frame {i} ends, using: 0.26786208152770996\n",
      "Frame 32 starts\n",
      "Draw pegs uses: 0.08698487281799316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 139.6ms\n",
      "Speed: 1.7ms preprocess, 139.6ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.1663060188293457\n",
      "Frame {i} ends, using: 0.2558560371398926\n",
      "Frame 33 starts\n",
      "Draw pegs uses: 0.08172225952148438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 reed, 1 wire, 128.0ms\n",
      "Speed: 1.7ms preprocess, 128.0ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.15077877044677734\n",
      "Frame {i} ends, using: 0.23501896858215332\n",
      "Frame 34 starts\n",
      "Draw pegs uses: 0.0880131721496582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 battery, 1 led, 1 reed, 1 wire, 139.9ms\n",
      "Speed: 2.5ms preprocess, 139.9ms inference, 0.6ms postprocess per image at shape (1, 3, 800, 480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO object detection uses: 0.17009592056274414\n",
      "Frame {i} ends, using: 0.26123499870300293\n",
      "Frame 35 starts\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Assuming you have the matrix results_transferred ready\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mdraw_virtual_board_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIMG_9955.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mprint_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 34\u001b[0m, in \u001b[0;36mdraw_virtual_board_video\u001b[0;34m(source, show, print_time, frame_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Draw pegs, return a mapping between matrix and real coordinates\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m matrixcoor_to_realcoor, frame_tilt, frame_circle \u001b[38;5;241m=\u001b[39m \u001b[43mdraws_pegs_on_rotated_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_time:\n\u001b[1;32m     36\u001b[0m     draw_peg_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[51], line 77\u001b[0m, in \u001b[0;36mdraws_pegs_on_rotated_board\u001b[0;34m(image, draw_edge)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#time2=time.time()\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#print(\"masking and calculate angle time:\", time2-time1)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m boardBW_tilt \u001b[38;5;241m=\u001b[39m tilt(boardBW, angle) \n\u001b[0;32m---> 77\u001b[0m image_tilt \u001b[38;5;241m=\u001b[39m \u001b[43mtilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#time3=time.time()\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#print(\"deskew time:\", time3-time2)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# cv2.imwrite('board_deskew.png',image_tilt)  \u001b[39;00m\n\u001b[1;32m     81\u001b[0m         \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#get the max edges of the board then draw edges and pegs on it\u001b[39;00m\n\u001b[1;32m     83\u001b[0m x1,x2,y1,y2 \u001b[38;5;241m=\u001b[39m get_edges(boardBW_tilt)\n",
      "Cell \u001b[0;32mIn[51], line 20\u001b[0m, in \u001b[0;36mtilt\u001b[0;34m(image, angle)\u001b[0m\n\u001b[1;32m     18\u001b[0m center \u001b[38;5;241m=\u001b[39m (w \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     19\u001b[0m M \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetRotationMatrix2D(center, angle, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m rotated \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarpAffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_CUBIC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborderMode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBORDER_REPLICATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rotated\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def draw_virtual_board_video(source=0,show=False,print_time=False,frame_rate=10):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    model = YOLO('best (5).pt')\n",
    "    i = 0\n",
    "    prev = 0\n",
    "    \n",
    "    while True:\n",
    "        # Capture a frame\n",
    "        ret, frame = cap.read()\n",
    "        if show:\n",
    "            print(i)\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        time_elapsed = time.time() - prev\n",
    "        if time_elapsed > 1./frame_rate:\n",
    "            prev = time.time()\n",
    "        \n",
    "            # Convert the raw frame to PIL Image\n",
    "            #raw_frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            # Reflect the raw frame horizontally and Rotate the raw frame 90 degrees counterclockwise\n",
    "            #raw_frame_pil = raw_frame_pil.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            #raw_frame_pil = raw_frame_pil.rotate(90, expand=True)\n",
    "            \n",
    "            # Convert the frame to RGB for PIL (optional)\n",
    "            # frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            start_time = time.time()\n",
    "            if print_time:\n",
    "                print(f\"Frame {i} starts\")\n",
    "                \n",
    "\n",
    "            # Draw pegs, return a mapping between matrix and real coordinates\n",
    "            matrixcoor_to_realcoor, frame_tilt, frame_circle = draws_pegs_on_rotated_board(frame)\n",
    "            if print_time:\n",
    "                draw_peg_time = time.time()\n",
    "                print(\"Draw pegs uses:\", draw_peg_time - start_time)\n",
    "\n",
    "            # Use YOLO object detection to get position\n",
    "            results = model.predict(frame_tilt,show=True,conf=0.2)\n",
    "            if print_time:\n",
    "                print(\"YOLO object detection uses:\", time.time()-draw_peg_time)\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                output = np.hstack([boxes.xyxy, boxes.cls[:, np.newaxis]])\n",
    "\n",
    "            # Get the mapping between matrix entries and class, then draw the virtual board\n",
    "            matrix = matrix_class_mapping(output, matrixcoor_to_realcoor)\n",
    "            final_image = show_estimated_board(matrix)\n",
    "\n",
    "            # Convert the image back to BGR format for displaying with OpenCV\n",
    "            final_image_bgr = cv2.cvtColor(np.array(final_image), cv2.COLOR_RGB2BGR)\n",
    "            #raw_frame_pil = cv2.cvtColor(np.array(raw_frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Display the raw board and virtual board outputs in separate windows\n",
    "            # cv2.imshow(\"Raw Board\", np.array(raw_frame_pil))\n",
    "            cv2.imshow(\"Virtual Board\", final_image_bgr)\n",
    "            \n",
    "            if print_time:\n",
    "                end_time = time.time()\n",
    "                time_elapsed = end_time - start_time\n",
    "                print(\"Frame {i} ends, using:\", time_elapsed)\n",
    "            i += 1\n",
    "            # Wait for the specified interval time\n",
    "            #time.sleep(interval_seconds)\n",
    "\n",
    "            # Check for the 'q' key press to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release the webcam and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Assuming you have the matrix results_transferred ready\n",
    "draw_virtual_board_video(source='IMG_9955.mp4',print_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x480 1 led, 1 motor, 1 push button, 4 wires, 153.3ms\n",
      "Speed: 3.4ms preprocess, 153.3ms inference, 0.7ms postprocess per image at shape (1, 3, 800, 480)\n"
     ]
    }
   ],
   "source": [
    "def draw_virtual_board_video(source=0,show=False,frame_rate=20):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    model = YOLO('best (5).pt')\n",
    "    prev = 0\n",
    "    \n",
    "    while True:\n",
    "        time_elapsed = time.time() - prev\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if time_elapsed > 1./frame_rate:\n",
    "            prev = time.time()\n",
    "            # Draw pegs, return a mapping between matrix and real coordinates\n",
    "            matrixcoor_to_realcoor, frame_tilt, frame_circle = draws_pegs_on_rotated_board(frame)\n",
    "\n",
    "            # Use YOLO object detection to get position\n",
    "            results = model.predict(frame_tilt,show=True)\n",
    "\n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                output = np.hstack([boxes.xyxy, boxes.cls[:, np.newaxis]])\n",
    "                if show:\n",
    "                    print(output)\n",
    "\n",
    "            # Get the mapping between matrix entries and class, then draw the virtual board\n",
    "            matrix = matrix_class_mapping(output, matrixcoor_to_realcoor)\n",
    "            final_image = show_estimated_board(matrix)\n",
    "\n",
    "            # Convert the image back to BGR format for displaying with OpenCV\n",
    "            final_image_bgr = cv2.cvtColor(np.array(final_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Display the raw board and virtual board outputs in separate windows\n",
    "            cv2.imshow(\"Virtual Board\", final_image_bgr)\n",
    "            \n",
    "\n",
    "            # Check for the 'q' key press to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release the webcam and close the windows\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Assuming you have the matrix results_transferred ready\n",
    "draw_virtual_board_video(source='IMG_9951.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
