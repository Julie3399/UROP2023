{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatAngle(boardBW):\n",
    "    \n",
    "\tcoords = np.column_stack(np.where(boardBW > 0))\n",
    "\tangle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "\tif angle < -45:\n",
    "\t\tangle = -(90 + angle)\n",
    "\t \n",
    "\telse:\n",
    "\t\tangle = -angle\n",
    "\t\t\n",
    "\treturn angle\n",
    "\n",
    "\n",
    "def tilt(image, angle):\n",
    "    \t# rotate the image to deskew it\n",
    "\t(h, w) = image.shape[:2]\n",
    "\tcenter = (w // 2, h // 2)\n",
    "\tM = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\trotated = cv2.warpAffine(image, M, (w, h),\n",
    "\tflags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\treturn rotated\n",
    "\n",
    "# def whatAngle(boardBW):\n",
    "#     coords = np.column_stack(np.where(boardBW > 0))\n",
    "#     rect = cv2.minAreaRect(coords)\n",
    "\n",
    "#     # Get the angle from the minimum bounding rectangle\n",
    "#     angle = rect[-1]\n",
    "\n",
    "#     # Calculate the aspect ratio of the bounding rectangle\n",
    "#     width, height = rect[1]\n",
    "#     aspect_ratio = max(width, height) / min(width, height)\n",
    "\n",
    "#     # Determine the desired orientation (longer side should be horizontal)\n",
    "#     if aspect_ratio > 1:\n",
    "#         # The longer side is vertical, we need to make it horizontal\n",
    "#         if angle < -45:\n",
    "#             angle = -(90 + angle)\n",
    "#         else:\n",
    "#             angle = -angle\n",
    "#     else:\n",
    "#         # The longer side is already horizontal, we need to make it vertical\n",
    "#         angle = -(90 + angle)\n",
    "\n",
    "#     return angle\n",
    "\n",
    "# def tilt(image, angle):\n",
    "#     # Make a copy of the image to avoid modifying the original\n",
    "#     rotated_image = image.copy()\n",
    "\n",
    "#     # Rotate the copied image to deskew it\n",
    "#     (h, w) = rotated_image.shape[:2]\n",
    "#     center = (w // 2, h // 2)\n",
    "#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "#     rotated = cv2.warpAffine(rotated_image, M, (w, h),\n",
    "#                              flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "#     return rotated\n",
    "\n",
    "\n",
    "def get_edges(image):\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Get the indices of non-zero elements (edge points)\n",
    "    non_zero_indices = np.nonzero(image_array)\n",
    "\n",
    "    # Get the minimum and maximum row and column indices of non-zero elements\n",
    "    minRow, minColumn = np.min(non_zero_indices, axis=1)\n",
    "    maxRow, maxColumn = np.max(non_zero_indices, axis=1)\n",
    "\n",
    "    extLeft = minColumn\n",
    "    extRight = maxColumn\n",
    "    extTop = minRow\n",
    "    extBot = maxRow\n",
    "    return (extLeft, extRight, extBot, extTop)\n",
    "\n",
    "def get_board_mask(img):\n",
    "    color = [0, 0, 0, 255, 255, 50]\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array(color[:3])  \n",
    "    upper = np.array(color[3:]) \n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def get_pegs(img,x1,x2,y1,y2):\n",
    "    matrixcoor_to_realcoor = {}\n",
    "    dist_from_edge = [(x2-x1)/13,(y2-y1)/15]\n",
    "    board_width = x2-x1-2*dist_from_edge[0]\n",
    "    board_height = y2-y1-2*dist_from_edge[1]\n",
    "    horizontal_interval = board_width / 12\n",
    "    vertical_interval = board_height / 14\n",
    "    img_circle = img.copy()\n",
    "    \n",
    "    # relate matrix coordinate to real peg coordinate\n",
    "    for i in range(0,13):\n",
    "        for j in range(0,15):\n",
    "            matrixcoor_to_realcoor[i,j] = np.array([x1 + int(horizontal_interval * i + dist_from_edge[0]), y1 + int(vertical_interval * j + dist_from_edge[1])])\n",
    "    \n",
    "    for key in matrixcoor_to_realcoor:\n",
    "        cv2.circle(img_circle, matrixcoor_to_realcoor[key], 2, (200, 200, 200), -1)\n",
    "    \n",
    "    return img_circle,matrixcoor_to_realcoor\n",
    "\n",
    "def draws_pegs_on_rotated_board(image,draw_edge=False,output_get_pegs=None):\n",
    "    \n",
    "    if not output_get_pegs:\n",
    "        #time1=time.time()\n",
    "        boardBW = get_board_mask(image)\n",
    "        angle = whatAngle(boardBW)\n",
    "        #time2=time.time()\n",
    "        #print(\"masking and calculate angle time:\", time2-time1)\n",
    "        boardBW_tilt = tilt(boardBW, angle) \n",
    "        image_tilt = tilt(image, angle) \n",
    "        #time3=time.time()\n",
    "        #print(\"deskew time:\", time3-time2)\n",
    "        # cv2.imwrite('board_deskew.png',image_tilt)  \n",
    "                \n",
    "        #get the max edges of the board then draw edges and pegs on it\n",
    "        x1,x2,y1,y2 = get_edges(boardBW_tilt)\n",
    "        #time4=time.time()\n",
    "        #print(\"get_edges:\", time4-time3)\n",
    "        img_circle, matrixcoor_to_realcoor = get_pegs(image_tilt,x1,x2,y1,y2)\n",
    "    else:\n",
    "        img_circle, matrixcoor_to_realcoor,x1,y1,x2,y2 = output_get_pegs\n",
    "    \n",
    "    #time5=time.time()\n",
    "    #print(\"get_pegs:\", time5-time4)\n",
    "    \n",
    "    if draw_edge:\n",
    "        cv2.rectangle(img_circle, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "    # cv2.imwrite('board_with_pegs.png',img_circle)    \n",
    "    return matrixcoor_to_realcoor, img_circle\n",
    "\n",
    "def round_to_integer_with_error(float_number, error_rate = 0.3, down = True):\n",
    "    if down:\n",
    "        lower_integer = int(float_number)\n",
    "\n",
    "        # Calculate the error between the float number and the lower integer\n",
    "        error = float_number - lower_integer\n",
    "\n",
    "        # Check if the error is within the custom error rate\n",
    "        if error <= error_rate:\n",
    "            return lower_integer - 1\n",
    "        else:\n",
    "            return lower_integer \n",
    "    else:\n",
    "        upper_integer = np.ceil(float_number).astype(int)\n",
    "\n",
    "        # Calculate the error between the float number and the upper integer\n",
    "        error = upper_integer - float_number\n",
    "\n",
    "        # Check if the error is within the custom error rate\n",
    "        if error <= error_rate:\n",
    "            return upper_integer + 1\n",
    "        else:\n",
    "            return upper_integer\n",
    "\n",
    "# def translate_coordinates(r):\n",
    "#     x1,y1,x2,y2,class_id = r\n",
    "#     grid_x1 = round_to_integer_with_error(((x1-x0) / x_len) * 12,down=False)\n",
    "#     grid_y1 = round_to_integer_with_error(((y1-y0) / y_len) * 14,down=False)\n",
    "#     grid_x2 = round_to_integer_with_error(((x2-x0) / x_len) * 12)\n",
    "#     grid_y2 = round_to_integer_with_error(((y2-y0) / y_len) * 14)\n",
    "#     # if class_id == 11:\n",
    "#     #     print(\"x1:\",((x1-x0) / x_len) * 12,grid_x1)\n",
    "#     #     print(\"y1:\",((y1-y0) / y_len) * 14,grid_y1)\n",
    "#     #     print(\"x2:\",((x2-x0) / x_len) * 12,grid_x2)\n",
    "#     #     print(\"y2:\",((y2-y0) / y_len) * 14,grid_y2)\n",
    "        \n",
    "#     grid_x2 = max(grid_x1,grid_x2)\n",
    "#     grid_y2 = max(grid_y1,grid_y2)\n",
    "\n",
    "#     grid_x1 = max(0, min(grid_x1, 12 - 1))\n",
    "#     grid_y1 = max(0, min(grid_y1, 14 - 1))\n",
    "#     grid_x2 = max(0, min(grid_x2, 12 - 1))\n",
    "#     grid_y2 = max(0, min(grid_y2, 14 - 1))\n",
    "    \n",
    "#     return 12-grid_x2, 12-grid_x1,grid_y1,grid_y2\n",
    "\n",
    "def matrix_class_mapping(results,matrixcoor_to_realcoor):\n",
    "    x0,y0 = matrixcoor_to_realcoor[(0,14)]\n",
    "    matrix = np.zeros((13, 15))-1\n",
    "    x_len, y_len = np.abs(matrixcoor_to_realcoor[(0,0)]-matrixcoor_to_realcoor[(12,14)])\n",
    "    results = sorted(results,key = lambda x:x[-1])\n",
    "\n",
    "    for r in results:\n",
    "        x1,y1,x2,y2,class_id = r\n",
    "        grid_x1 = round_to_integer_with_error(((x1-x0) / x_len) * 12,down=False)\n",
    "        grid_y1 = round_to_integer_with_error(((y1-y0) / y_len) * 14,down=False)\n",
    "        grid_x2 = round_to_integer_with_error(((x2-x0) / x_len) * 12)\n",
    "        grid_y2 = round_to_integer_with_error(((y2-y0) / y_len) * 14)\n",
    "        # if class_id == 11:\n",
    "        #     print(\"x1:\",((x1-x0) / x_len) * 12,grid_x1)\n",
    "        #     print(\"y1:\",((y1-y0) / y_len) * 14,grid_y1)\n",
    "        #     print(\"x2:\",((x2-x0) / x_len) * 12,grid_x2)\n",
    "        #     print(\"y2:\",((y2-y0) / y_len) * 14,grid_y2)\n",
    "        \n",
    "        grid_x2 = max(grid_x1,grid_x2)\n",
    "        grid_y2 = max(grid_y1,grid_y2)\n",
    "\n",
    "        grid_x1 = max(0, min(grid_x1, 12))\n",
    "        grid_y1 = max(0, min(grid_y1, 14))\n",
    "        grid_x2 = max(0, min(grid_x2, 12))\n",
    "        grid_y2 = max(0, min(grid_y2, 14))\n",
    "    \n",
    "        matrix[12-grid_x2:12-grid_x1+1,grid_y1:grid_y2+1]=class_id\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "color_mapping = {\n",
    "    0: 'red', # done, battery\n",
    "    1: 'black', # board\n",
    "    2: 'green', # done, buzzer\n",
    "    3: 'orange',\n",
    "    4: 'limegreen', #done, fm\n",
    "    5: 'grey', # done (lamp; check accuracy)\n",
    "    6: 'darkred', # done, led\n",
    "    7: 'blue', # mc\n",
    "    8: 'yellow', # done, motor\n",
    "    9: 'royalblue', # done, push button\n",
    "    10: 'seagreen', # done, reed\n",
    "    11: 'firebrick', # done, speaker\n",
    "    12: 'darkgreen', # done, switch\n",
    "    13: 'purple' # done, wire\n",
    "}\n",
    "\n",
    "def show_estimated_board(results_transferred,color_mapping=color_mapping,rows = 13,cols = 15,cell_size = 50):\n",
    "    \"\"\"Draw the virtual image of the board\n",
    "\n",
    "    Args:\n",
    "        results_transferred (matrix): a matrix to store class of each block of the board\n",
    "        rows (int, optional): number of rows of the grid. Defaults to 8.\n",
    "        cols (int, optional): number of columns of the grid. Defaults to 7.\n",
    "        cell_size (int, optional): size of cell. Defaults to 50.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total size of the image\n",
    "    image_width = cols * cell_size\n",
    "    image_height = rows * cell_size\n",
    "\n",
    "    # Create a new image with a black background\n",
    "    image = Image.new(\"RGB\", (image_width, image_height), color=\"black\")\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Draw the grid with numbers\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate the position of the top-left corner of the cell\n",
    "            x1 = col * cell_size\n",
    "            y1 = row * cell_size\n",
    "\n",
    "            # Calculate the position of the bottom-right corner of the cell\n",
    "            x2 = x1 + cell_size\n",
    "            y2 = y1 + cell_size\n",
    "\n",
    "            # Calculate the number for each cell (you can use any logic here)\n",
    "            cell_number = results_transferred[row][col]\n",
    "\n",
    "            # Draw the cell with the corresponding number\n",
    "            if cell_number >= 0:\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=color_mapping[cell_number],outline='white')\n",
    "            else:\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=\"black\",outline='white')\n",
    "            draw.text((x1 + 20, y1 + 20), str(cell_number),  fill=\"white\")\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the image using cv2.imread()\n",
    "# image_path = 'raw11.png'\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # Get the necessary images and mapping using draws_pegs_on_rotated_board\n",
    "# matrixcoor_to_realcoor, image_tilt, img_circle = draws_pegs_on_rotated_board(image)\n",
    "\n",
    "# # Convert the image_tilt and img_circle (NumPy arrays) to PIL Image objects for display\n",
    "# image_tilt_pil = Image.fromarray(cv2.cvtColor(image_tilt, cv2.COLOR_BGR2RGB))\n",
    "# img_circle_pil = Image.fromarray(cv2.cvtColor(img_circle, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# # Display the images\n",
    "# image_tilt_pil.show()\n",
    "# img_circle_pil.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "1. Wires not very accurate (more training or use masking)\n",
    "2. Too slow (Solved)\n",
    "3. Sometimes the shape of pieces is not correct, e.g. speaker to 2 columns\n",
    "\n",
    "Note that:\n",
    "1. When placing battery, at most at the second last column \n",
    "2. Use board with pegs to check whether the board is not skewed due to angle of the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_video(cap):\n",
    "    if not os.path.exists('raw_videos'):\n",
    "            os.makedirs('raw_videos')\n",
    "            \n",
    "    # Get the list of existing files in the \"cropped_frames\" directory\n",
    "    existing_files = os.listdir('raw_videos')\n",
    "    if existing_files:\n",
    "        video_count = max([int(file_name.split('_')[2].split('.')[0]) for file_name in existing_files]) + 1\n",
    "    else:\n",
    "        video_count = 0\n",
    "        \n",
    "    # Create a VideoWriter to save the cropped video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    output_path = os.path.join('raw_videos', f\"raw_video_{video_count}.mp4\")\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 257.3ms\n",
      "Speed: 8.2ms preprocess, 257.3ms inference, 37.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 219.5ms\n",
      "Speed: 2.6ms preprocess, 219.5ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 194.0ms\n",
      "Speed: 2.3ms preprocess, 194.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 193.3ms\n",
      "Speed: 2.2ms preprocess, 193.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 195.9ms\n",
      "Speed: 1.9ms preprocess, 195.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 191.8ms\n",
      "Speed: 2.1ms preprocess, 191.8ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 198.3ms\n",
      "Speed: 2.1ms preprocess, 198.3ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.6ms\n",
      "Speed: 2.2ms preprocess, 189.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 196.5ms\n",
      "Speed: 2.2ms preprocess, 196.5ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 190.7ms\n",
      "Speed: 2.0ms preprocess, 190.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 195.3ms\n",
      "Speed: 2.1ms preprocess, 195.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 195.2ms\n",
      "Speed: 2.3ms preprocess, 195.2ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.7ms\n",
      "Speed: 2.2ms preprocess, 188.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 194.0ms\n",
      "Speed: 2.1ms preprocess, 194.0ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 193.8ms\n",
      "Speed: 2.2ms preprocess, 193.8ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.6ms\n",
      "Speed: 2.1ms preprocess, 187.6ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.7ms\n",
      "Speed: 2.3ms preprocess, 187.7ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 187.9ms\n",
      "Speed: 2.0ms preprocess, 187.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 185.2ms\n",
      "Speed: 2.2ms preprocess, 185.2ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.4ms\n",
      "Speed: 2.1ms preprocess, 189.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 187.7ms\n",
      "Speed: 2.4ms preprocess, 187.7ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.8ms\n",
      "Speed: 2.4ms preprocess, 188.8ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 243.0ms\n",
      "Speed: 1.9ms preprocess, 243.0ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 217.2ms\n",
      "Speed: 2.2ms preprocess, 217.2ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 182.5ms\n",
      "Speed: 2.2ms preprocess, 182.5ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 184.1ms\n",
      "Speed: 1.9ms preprocess, 184.1ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 184.3ms\n",
      "Speed: 2.5ms preprocess, 184.3ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 182.6ms\n",
      "Speed: 2.0ms preprocess, 182.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 183.1ms\n",
      "Speed: 2.4ms preprocess, 183.1ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.0ms\n",
      "Speed: 2.2ms preprocess, 187.0ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 182.0ms\n",
      "Speed: 2.3ms preprocess, 182.0ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.4ms\n",
      "Speed: 2.1ms preprocess, 187.4ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 193.7ms\n",
      "Speed: 2.2ms preprocess, 193.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.1ms\n",
      "Speed: 2.2ms preprocess, 188.1ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 185.9ms\n",
      "Speed: 2.0ms preprocess, 185.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 186.7ms\n",
      "Speed: 2.1ms preprocess, 186.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 185.1ms\n",
      "Speed: 2.3ms preprocess, 185.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 184.2ms\n",
      "Speed: 2.1ms preprocess, 184.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 183.1ms\n",
      "Speed: 2.1ms preprocess, 183.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "/opt/homebrew/lib/python3.11/site-packages/google/protobuf/symbol_database.py:78: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 212.0ms\n",
      "Speed: 3.3ms preprocess, 212.0ms inference, 0.9ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 190.7ms\n",
      "Speed: 1.9ms preprocess, 190.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.8ms\n",
      "Speed: 2.0ms preprocess, 188.8ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 186.1ms\n",
      "Speed: 2.3ms preprocess, 186.1ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 187.9ms\n",
      "Speed: 2.1ms preprocess, 187.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 187.7ms\n",
      "Speed: 2.1ms preprocess, 187.7ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 187.8ms\n",
      "Speed: 2.4ms preprocess, 187.8ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.4ms\n",
      "Speed: 2.0ms preprocess, 188.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 190.3ms\n",
      "Speed: 2.3ms preprocess, 190.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.8ms\n",
      "Speed: 2.0ms preprocess, 189.8ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 190.5ms\n",
      "Speed: 2.3ms preprocess, 190.5ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 190.6ms\n",
      "Speed: 2.1ms preprocess, 190.6ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 184.4ms\n",
      "Speed: 2.4ms preprocess, 184.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 193.2ms\n",
      "Speed: 1.9ms preprocess, 193.2ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 197.3ms\n",
      "Speed: 1.9ms preprocess, 197.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 186.4ms\n",
      "Speed: 2.6ms preprocess, 186.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.2ms\n",
      "Speed: 2.4ms preprocess, 189.2ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 192.1ms\n",
      "Speed: 2.1ms preprocess, 192.1ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 184.1ms\n",
      "Speed: 2.1ms preprocess, 184.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.0ms\n",
      "Speed: 1.9ms preprocess, 188.0ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.3ms\n",
      "Speed: 2.1ms preprocess, 188.3ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.1ms\n",
      "Speed: 2.1ms preprocess, 187.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 190.5ms\n",
      "Speed: 1.9ms preprocess, 190.5ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 190.4ms\n",
      "Speed: 2.3ms preprocess, 190.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 194.6ms\n",
      "Speed: 2.1ms preprocess, 194.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 191.3ms\n",
      "Speed: 2.1ms preprocess, 191.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 193.2ms\n",
      "Speed: 2.0ms preprocess, 193.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 233.1ms\n",
      "Speed: 2.0ms preprocess, 233.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 185.6ms\n",
      "Speed: 2.3ms preprocess, 185.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 203.3ms\n",
      "Speed: 2.3ms preprocess, 203.3ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.7ms\n",
      "Speed: 2.0ms preprocess, 189.7ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 186.7ms\n",
      "Speed: 2.2ms preprocess, 186.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 192.6ms\n",
      "Speed: 2.3ms preprocess, 192.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.0ms\n",
      "Speed: 2.2ms preprocess, 188.0ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 191.1ms\n",
      "Speed: 2.0ms preprocess, 191.1ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 198.8ms\n",
      "Speed: 2.0ms preprocess, 198.8ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 192.3ms\n",
      "Speed: 1.9ms preprocess, 192.3ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 187.6ms\n",
      "Speed: 2.1ms preprocess, 187.6ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 196.4ms\n",
      "Speed: 2.2ms preprocess, 196.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.7ms\n",
      "Speed: 2.1ms preprocess, 188.7ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.1ms\n",
      "Speed: 2.0ms preprocess, 188.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 193.8ms\n",
      "Speed: 2.0ms preprocess, 193.8ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 189.1ms\n",
      "Speed: 2.4ms preprocess, 189.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 194.0ms\n",
      "Speed: 2.4ms preprocess, 194.0ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 199.1ms\n",
      "Speed: 2.2ms preprocess, 199.1ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 190.3ms\n",
      "Speed: 2.0ms preprocess, 190.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.3ms\n",
      "Speed: 1.9ms preprocess, 188.3ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 191.7ms\n",
      "Speed: 2.1ms preprocess, 191.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 188.1ms\n",
      "Speed: 2.3ms preprocess, 188.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.5ms\n",
      "Speed: 2.2ms preprocess, 189.5ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 200.4ms\n",
      "Speed: 2.9ms preprocess, 200.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.6ms\n",
      "Speed: 2.4ms preprocess, 188.6ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 193.6ms\n",
      "Speed: 2.0ms preprocess, 193.6ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 195.7ms\n",
      "Speed: 2.0ms preprocess, 195.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 189.0ms\n",
      "Speed: 2.2ms preprocess, 189.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 191.5ms\n",
      "Speed: 2.3ms preprocess, 191.5ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 194.5ms\n",
      "Speed: 2.0ms preprocess, 194.5ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 183.3ms\n",
      "Speed: 2.0ms preprocess, 183.3ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 190.5ms\n",
      "Speed: 2.0ms preprocess, 190.5ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 194.4ms\n",
      "Speed: 2.2ms preprocess, 194.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 188.3ms\n",
      "Speed: 2.2ms preprocess, 188.3ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 191.8ms\n",
      "Speed: 2.0ms preprocess, 191.8ms inference, 0.4ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 lamp, 1 switch, 2 wires, 218.2ms\n",
      "Speed: 2.4ms preprocess, 218.2ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 208.9ms\n",
      "Speed: 2.1ms preprocess, 208.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 184.2ms\n",
      "Speed: 2.2ms preprocess, 184.2ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 736x800 1 battery, 1 switch, 2 wires, 191.5ms\n",
      "Speed: 2.2ms preprocess, 191.5ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 800)\n"
     ]
    }
   ],
   "source": [
    "def draw_virtual_board_video(source=0,show_pegs=False,print_time=False,frame_rate=5,store=False):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    model = YOLO('best (8).pt')\n",
    "    i = 0\n",
    "    prev = 0\n",
    "    \n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands()\n",
    "    \n",
    "    if store:\n",
    "        writer = store_video(cv2.VideoCapture(source))\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        # Capture a frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Camera Connection Failed\")\n",
    "            break\n",
    "        \n",
    "        if store:\n",
    "            writer.write(frame)\n",
    "\n",
    "        # Read the video properties to get the frame width and height\n",
    "        crop_x, crop_y, crop_width, crop_height = 760, 250, 450, 500\n",
    "        frame_for_veri = frame[crop_y:crop_y + crop_height, crop_x:crop_x + crop_width]\n",
    "        frame_for_hand = frame[crop_y:crop_y + crop_height, crop_x:crop_x + crop_width+150]\n",
    "        frame = cv2.rotate(frame_for_veri, cv2.ROTATE_90_CLOCKWISE)\n",
    "        cv2.imshow(\"Raw Image\", frame)\n",
    "        \n",
    "        # Detecting hand\n",
    "        results = hands.process(cv2.cvtColor(frame_for_hand, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_hand_landmarks:\n",
    "            # If a hand is detected, skip this frame\n",
    "            continue\n",
    "        \n",
    "        time_elapsed = time.time() - prev\n",
    "        if time_elapsed > 1./frame_rate:\n",
    "            prev = time.time()\n",
    "        \n",
    "            # Convert the raw frame to PIL Image\n",
    "            #raw_frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            # Reflect the raw frame horizontally and Rotate the raw frame 90 degrees counterclockwise\n",
    "            #raw_frame_pil = raw_frame_pil.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            #raw_frame_pil = raw_frame_pil.rotate(90, expand=True)\n",
    "            \n",
    "            # Convert the frame to RGB for PIL (optional)\n",
    "            # frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            start_time = time.time()\n",
    "            if print_time:\n",
    "                print(f\"Frame {i} starts\")\n",
    "            \n",
    "            # to-do: make this part into function\n",
    "            boardBW = get_board_mask(frame)\n",
    "            angle = whatAngle(boardBW)\n",
    "            boardBW_tilt = tilt(boardBW, angle) \n",
    "            frame_tilt = tilt(frame, angle) \n",
    "\n",
    "            # if i == 0:\n",
    "            #     x1,x2,y1,y2 = get_edges(boardBW_tilt)\n",
    "            #     out1,out2 = get_pegs(frame_tilt,x1,x2,y1,y2)       \n",
    "            #     output_get_pegs=[out1,out2, x1,y1,x2,y2]     \n",
    "            \n",
    "            # Draw pegs, return a mapping between matrix and real coordinates\n",
    "            matrixcoor_to_realcoor, frame_circle = draws_pegs_on_rotated_board(frame) # output_get_pegs = output_get_pegs\n",
    "            if print_time:\n",
    "                draw_peg_time = time.time()\n",
    "                print(\"Draw pegs uses:\", draw_peg_time - start_time)\n",
    "\n",
    "            # Use YOLO object detection to get position\n",
    "            results = model.predict(frame_tilt,show=True,conf=0.3)\n",
    "            if print_time:\n",
    "                print(\"YOLO object detection uses:\", time.time()-draw_peg_time)\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                output = np.hstack([boxes.xyxy, boxes.cls[:, np.newaxis]])\n",
    "\n",
    "            # Get the mapping between matrix entries and class, then draw the virtual board\n",
    "            matrix = matrix_class_mapping(output, matrixcoor_to_realcoor)\n",
    "            final_image = show_estimated_board(matrix)\n",
    "\n",
    "            # Convert the image back to BGR format for displaying with OpenCV\n",
    "            final_image_bgr = cv2.cvtColor(np.array(final_image), cv2.COLOR_RGB2BGR)\n",
    "            #raw_frame_pil = cv2.cvtColor(np.array(raw_frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Display the raw board and virtual board outputs in separate windows\n",
    "            # cv2.imshow(\"Raw Board\", np.array(raw_frame_pil))\n",
    "            cv2.imshow(\"Virtual Board\", final_image_bgr)\n",
    "            if show_pegs:\n",
    "                cv2.imshow(\"Board with Pegs\",frame_circle)\n",
    "            \n",
    "            if print_time:\n",
    "                end_time = time.time()\n",
    "                time_elapsed = end_time - start_time\n",
    "                print(\"Frame {i} ends, using:\", time_elapsed)\n",
    "            i += 1\n",
    "            # Wait for the specified interval time\n",
    "            #time.sleep(interval_seconds)\n",
    "\n",
    "        # Check for the 'q' key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close the windows\n",
    "    cap.release()\n",
    "    if store:\n",
    "        writer.release() \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Assuming you have the matrix results_transferred ready\n",
    "# draw_virtual_board_video(source='raw_videos/raw_video_5.mp4', show_pegs=True)\n",
    "\n",
    "draw_virtual_board_video(source=0,show_pegs=True,store=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/google/protobuf/symbol_database.py:78: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m rgb_frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     25\u001b[0m \u001b[39m# Detect hands in the frame\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m results \u001b[39m=\u001b[39m hands\u001b[39m.\u001b[39;49mprocess(rgb_frame)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mmulti_hand_landmarks:\n\u001b[1;32m     29\u001b[0m     \u001b[39m# If a hand is detected, put text on the frame\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m#cv2.putText(frame, 'Hand Detected', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/mediapipe/python/solutions/hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[1;32m    133\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m         right hand) of the detected hand.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/mediapipe/python/solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    361\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[1;32m    362\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    363\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[1;32m    366\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[1;32m    369\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # Initialize mediapipe hands module\n",
    "# mp_hands = mp.solutions.hands\n",
    "# hands = mp_hands.Hands()\n",
    "\n",
    "# # Open a video capture object\n",
    "# video_capture = cv2.VideoCapture('raw_videos/raw_video_5.mp4')  # Replace with your video file path\n",
    "# delay = 0.2  # For example, 0.1 seconds\n",
    "\n",
    "# while video_capture.isOpened():\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Read the video properties to get the frame width and height\n",
    "#     crop_x, crop_y, crop_width, crop_height = 760, 250, 550, 500\n",
    "#     frame = frame[crop_y:crop_y + crop_height, crop_x:crop_x + crop_width]\n",
    "        \n",
    "#     # Convert the frame to RGB (mediapipe uses RGB images)\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Detect hands in the frame\n",
    "#     results = hands.process(rgb_frame)\n",
    "\n",
    "#     if results.multi_hand_landmarks:\n",
    "#         # If a hand is detected, put text on the frame\n",
    "#         #cv2.putText(frame, 'Hand Detected', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#         continue\n",
    "\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow('Frame', frame)\n",
    "\n",
    "#     time.sleep(delay)\n",
    "    \n",
    "#     # Exit the loop if 'q' key is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture object and close any open windows\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
