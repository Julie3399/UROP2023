{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains some function for facial recognition but required pre-training. That is to say, we have to use enough pictures of the two participants to collect the facial information of them. Then start recognition when needed. According to our current idea, it is not necessary to use any functions in this file although I will still provide some comments here in case you need them in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial detection using OpenCV and Haar Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(img):\n",
    "    '''\n",
    "    This function will draw a rectangular on the ddetected face.\n",
    "    '''\n",
    "    # convert to gray\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # load classifier\n",
    "    face_detector = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    # draw rectangle\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    # show image\n",
    "    cv.imshow('result', img)\n",
    "\n",
    "\n",
    "# read image\n",
    "# img = cv.imread('your_image_path')\n",
    "# face_detect()\n",
    "\n",
    "# use webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    flag, frame = cap.read()\n",
    "    if not flag:\n",
    "        break\n",
    "    face_detect(frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code using OpenCV (cv2) for capturing images from a camera feed and saving them when a specific key 'S' is pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Flag and starting number for image filenames\n",
    "flag, num = 1,31 # 31 means that the first 30 images is for another participants\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    suc, frame = cap.read()\n",
    "    cv.imshow(\"capture\", frame)\n",
    "    \n",
    "    # control the frequency of saving images\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == ord('s'):\n",
    "        cv.imwrite(\"Path_that_you_want_to_store_the_images\" + str(num) + \".name_of_participants\" + \".jpg\", frame)\n",
    "        num += 1\n",
    "        print(\"save image successfully!\")\n",
    "    elif k == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Recoded Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_images_and_labels(path):\n",
    "\n",
    "    # data for the faces\n",
    "    images = []\n",
    "    # data for the labels\n",
    "    labels = []\n",
    "    # get the path of all the files in the folder\n",
    "    # image_paths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    import glob\n",
    "    image_paths = [f for f in glob.glob('path_of_the_image_folder + /*.jpg')]\n",
    "    # if 'path_of_the_folder' + '.DS_Store' in image_paths:\n",
    "    #     image_paths.remove('path_of_the_folder' + '.DS_Store')\n",
    "    face_detect = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # go through all the image paths and load the images\n",
    "    for image_path in image_paths:\n",
    "        # load the image and convert it to grayscale, PIL has nine different modes\n",
    "        # L: 8-bit pixels, black and white\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        # convert PIL image to numpy array\n",
    "        image_numpy = np.array(image, 'uint8')\n",
    "        # get the data of the image\n",
    "        faces = face_detect.detectMultiScale(image_numpy, scaleFactor=1.1, minNeighbors=5)\n",
    "        # get the label of the image\n",
    "        label = int(os.path.split(image_path)[1].split(\".\")[0].replace(\" \", \"-\"))\n",
    "        # append the image to the list of images\n",
    "        for (x, y, w, h) in faces:\n",
    "            images.append(image_numpy[y:y+h, x:x+w])\n",
    "            labels.append(label)\n",
    "            cv.imshow('result', image_numpy[y:y+h, x:x+w])\n",
    "            cv.waitKey(100)\n",
    "    print(labels)\n",
    "    # return the images list and labels list\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "path = 'Your_path_here'\n",
    "images, labels = get_images_and_labels(path)\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(images, np.array(labels))\n",
    "# os.mkdir('training_data')\n",
    "recognizer.write('training_data/training_data.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "# load the recognizer file\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('PATH/training_data/training_data.yml')\n",
    "\n",
    "names = []\n",
    "warning_times = 0\n",
    "\n",
    "\n",
    "def face_detect_demo(img):\n",
    "    '''\n",
    "    Functions for detecting the face\n",
    "    '''\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    face_detector = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    face = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for x, y, w, h in face:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "        cv.circle(img, (x+w//2, y+h//2), min(w//2, h//2), (0, 0, 255), 1)\n",
    "\n",
    "        ids, confidence = recognizer.predict(gray[y:y+h, x:x+w])\n",
    "        if confidence < 100:\n",
    "            cv.putText(img, names[ids-1], (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv.LINE_AA)\n",
    "        else:\n",
    "            cv.putText(img, 'unknown', (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv.LINE_AA)\n",
    "        \n",
    "    cv.imshow('result', img)\n",
    "\n",
    "def name():\n",
    "    '''Get the name of the participants by using the image names'''\n",
    "    path = \"Path of the training image\"\n",
    "    image_paths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    for image_path in image_paths:\n",
    "        name = str(os.path.split(image_path)[1].split(\".\",2)[1])\n",
    "        names.append(name)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "name()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    face_detect_demo(frame)\n",
    "    if ord('q') == cv.waitKey(10):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "def detect(frame):\n",
    "    '''\n",
    "    detect the face with labeling: \"person 1\" & \"person 2\"\n",
    "    '''\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    face = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    person = 1\n",
    "    for x,y,w,h in face:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 1)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "    \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "\n",
    "    # return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detect(frame)\n",
    "    if ord('q') == cv2.waitKey(10):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
